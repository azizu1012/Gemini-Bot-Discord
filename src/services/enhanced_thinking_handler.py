"""Enhanced Thinking Handler - Handle THINKING block with 2-call strategy"""

import re
from typing import Optional, Dict, Any, Tuple
from src.core.logger import logger

async def precheck_search_needed(query: str, user_id: str) -> Tuple[bool, Optional[str]]:
    """PRE-CHECK: Before calling Gemini, detect if search is needed from user query
    
    Returns: (needs_search, search_query_expanded)
    """
    from src.services.dual_api_strategy import get_dual_api_strategy
    
    strategy = await get_dual_api_strategy()
    needs_search, search_query = await strategy.check_search_needed_from_query(query)
    
    if needs_search:
        logger.info(f"üîç PRE-CHECK: Search needed from query. User: {user_id}")
        return True, search_query
    
    return False, None

async def handle_thinking_with_dual_strategy(
    reply: str,
    user_id: str,
    query: str,
    messages: list,
    model_name: str,
    run_gemini_api_func,
) -> str:
    """Handle THINKING block with 2-call strategy
    
    Returns: Final response for user
    """
    from src.services.thinking_cache import get_thinking_cache
    from src.services.dual_api_strategy import get_dual_api_strategy
    
    thinking_cache = await get_thinking_cache()
    strategy = await get_dual_api_strategy()
    
    # 1. Extract THINKING block
    thinking_block_pattern = r'<THINKING>(.*?)</THINKING>'
    thinking_match = re.search(thinking_block_pattern, reply, re.DOTALL)
    
    original_thinking_content = ""
    default_thinking_content = ""
    
    if thinking_match:
        original_thinking_content = thinking_match.group(1).strip()
        logger.info(f"--- B·∫ÆT ƒê·∫¶U THINKING DEBUG CHO USER: {user_id} ---")
        logger.info(original_thinking_content)
        logger.info(f"--- K·∫æT TH√öC THINKING DEBUG ---")
    else:
        logger.warning(f"Kh√¥ng c√≥ THINKING block t·ª´ model. User: {user_id}")
        return reply  # Return as-is n·∫øu kh√¥ng c√≥ THINKING
    
    # 2. Cache THINKING block
    cache_key = await thinking_cache.save_thinking(user_id, original_thinking_content, query)
    logger.info(f"üíæ Cached THINKING block: {cache_key}")
    
    # 3. Ki·ªÉm tra xem c√≥ reply content ngo√†i THINKING kh√¥ng
    reply_final = re.sub(thinking_block_pattern, '', reply, flags=re.DOTALL).strip()
    
    if reply_final:
        # Model ƒë√£ tr·∫£ response ‚Üí kh√¥ng c·∫ßn g·ªçi l·∫°i
        logger.info(f"‚úÖ Model tr·∫£ response k√®m THINKING. User: {user_id}")
        return reply_final
    
    # 4. Ch·ªâ c√≥ THINKING ‚Üí ph√¢n t√≠ch xem c·∫ßn search kh√¥ng
    logger.warning(f"‚ö†Ô∏è M√¥ h√¨nh ch·ªâ tr·∫£ THINKING m√† kh√¥ng c√≥ response. Ph√¢n t√≠ch NEXT action. User: {user_id}")
    
    status, search_query = await strategy.analyze_thinking_for_next_action(original_thinking_content)
    
    if status == "READY":
        # Model s·∫µn s√†ng tr·∫£ l·ªùi d·ª±a tr√™n THINKING
        logger.info(f"Model s·∫µn s√†ng tr·∫£ l·ªùi t·ª´ THINKING. User: {user_id}")
        return _extract_answer_from_thinking(original_thinking_content)
    
    elif status == "NEED_SEARCH":
        # ==================== CALL 2: Search API ====================
        logger.info(f"üîç C·∫ßn t√¨m ki·∫øm th√™m. Query: {search_query}. User: {user_id}")
        
        if not search_query:
            search_query = query  # Fallback to original query
        
        search_results = await strategy.call_search_api(search_query, api_type="tavily")
        
        if not search_results:
            logger.warning(f"Search API tr·∫£ v·ªÅ k·∫øt qu·∫£ r·ªóng")
            search_results = "[Kh√¥ng t√¨m ƒë∆∞·ª£c th√¥ng tin m·ªõi]"
        
        # 5. Pass search results v·ªÅ Gemini (l·∫ßn 2)
        logger.info(f"üì§ G·ª≠i search results l·∫ßn 2 ƒë·∫øn Gemini. User: {user_id}")
        
        # Build message cho call 2
        search_message = strategy._build_search_only_message(original_thinking_content, search_results)
        
        # Prepare messages ƒë·ªÉ g·ªçi l·∫ßn 2 (ch·ªâ c·∫ßn user message + search results)
        messages_for_second_call = [
            {
                "role": "system",
                "content": "Based on search results, provide a direct answer in Vietnamese. Keep it friendly and concise."
            },
            {
                "role": "user",
                "content": search_message
            }
        ]
        
        # Call Gemini l·∫ßn 2 (T·ªöI ƒêA 2 CALLS!)
        final_response = await run_gemini_api_func(
            messages=messages_for_second_call,
            model_name=model_name,
            user_id=user_id,
            temperature=0.5,  # Lower temperature ƒë·ªÉ tr√°nh l·∫°c ƒë·ªÅ
            max_tokens=1500
        )
        
        if final_response and not final_response.startswith("L·ªói:"):
            # Lo·∫°i b·ªè THINKING block n·∫øu c√≥
            final_response = re.sub(thinking_block_pattern, '', final_response, flags=re.DOTALL).strip()
            logger.info(f"‚úÖ Call 2 th√†nh c√¥ng. User: {user_id}")
            return final_response
        else:
            logger.error(f"Call 2 th·∫•t b·∫°i: {final_response}")
            return _extract_answer_from_thinking(original_thinking_content)
    
    else:
        # UNKNOWN state
        logger.warning(f"Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c h√†nh ƒë·ªông. Tr√≠ch xu·∫•t answer t·ª´ THINKING.")
        return _extract_answer_from_thinking(original_thinking_content)


def _extract_answer_from_thinking(thinking_content: str) -> str:
    """Tr√≠ch xu·∫•t c√¢u tr·∫£ l·ªùi t·ª´ kh·ªëi THINKING
    
    T√¨m c√°c section:
    - K·∫øt lu·∫≠n / Conclusion
    - ƒê√°p √°n / Answer
    - Ph·∫ßn cu·ªëi c√πng (fallback)
    """
    thinking_lines = thinking_content.strip().split('\n')
    
    # T√¨m c√°c marker
    markers = [
        "K·∫øt lu·∫≠n:",
        "K·∫æT LU·∫¨N:",
        "Conclusion:",
        "CONCLUSION:",
        "ƒê√°p √°n:",
        "Answer:",
        "**K·∫øt qu·∫£:**",
    ]
    
    for marker in markers:
        for i, line in enumerate(thinking_lines):
            if marker in line:
                # L·∫•y t·ª´ d√≤ng n√†y tr·ªü ƒëi
                result = '\n'.join(thinking_lines[i+1:]).strip()
                if result:
                    return result
    
    # Fallback: l·∫•y 50% ph·∫ßn cu·ªëi
    middle = len(thinking_lines) // 2
    result = '\n'.join(thinking_lines[middle:]).strip()
    
    if not result:
        # Last resort
        result = thinking_lines[-1] if thinking_lines else "Xin l·ªói, kh√¥ng th·ªÉ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa b·∫°n"
    
    return result


def _is_only_thinking(reply: str) -> bool:
    """Ki·ªÉm tra xem reply ch·ªâ c√≥ THINKING block kh√¥ng"""
    thinking_pattern = r'<THINKING>.*?</THINKING>'
    # Remove THINKING block
    without_thinking = re.sub(thinking_pattern, '', reply, flags=re.DOTALL).strip()
    
    # N·∫øu ch·ªâ c√≤n whitespace ‚Üí l√† "only thinking"
    return len(without_thinking) < 50
